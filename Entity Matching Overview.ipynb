{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da1bb726",
   "metadata": {},
   "source": [
    "# Entity Matching Overview\n",
    "### Final Project for Kodołamacz's Data Science Bootcamp\n",
    "Author: Piotr Zioło"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec90cce",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "Entity matching (also known as record linkage) is the process of identifying which records in two or more datasets refer to the same real-world entity. High-quality entity matching allows organizations to consolidate information, eliminate duplicates, and gain a unified view of their data. Entity matching can be especially important in scenarios such as merging two lists of businesses from different CRMs of companies undergoing a merging process.\n",
    "\n",
    "In this project, we focus on matching restaurant entities from two restaurant guides: Fodor's and Zagat's. The goal is to determine which entries from the Fodor's restaurant list correspond to the same establishments in the Zagat's list. Since the two sources may use slightly different names, address formats, or phone number conventions for the same restaurant, simple joins on these fields would not guarantee accurate results. Thus, we will compare multiple more advanced approaches to entity matching:\n",
    "- Fuzzy String Matching – using string similarity (e.g. Levenshtein distance) primarily on textual fields like name.\n",
    "- TF–IDF + Cosine Similarity – treating restaurant records as documents and measuring cosine similarity of TF-IDF feature vectors.\n",
    "- Transformer Embeddings + Cosine – using pre-trained language model embeddings (Sentence-BERT) for each record and measuring vector cosine similarity.\n",
    "- Large Language Model – leveraging am LLM via API to semantically compare and decide if two descriptions refer to the same restaurant.\n",
    "- Supervised Machine Learning – training a classifier on labeled matching/non-matching record pairs, using multiple features (text similarity scores, etc.).\n",
    "\n",
    "We will evaluate each method on accuracy, precision, recall, and F1-score for identifying matches. We will also compare their runtime performance, scalability, and cost. By the end, we should understand which approach works best for this scenario and what the considerations are for deploying each at scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8d501f",
   "metadata": {},
   "source": [
    "### Dataset Overview\n",
    "The Fodor's–Zagat's restaurant dataset is a dataset designed to serve as a benchmark for entity matching evaluations. It was put together by Anna Primpeli and Christian Bizer of University of Mannheim in Germany.\n",
    "\n",
    "It consists of two lists of restaurants, one from Fodor's (533 entries) and one from Zagat's (331 entries). Each restaurant has the following attributes:\n",
    "- id (a unique identifier in each data source)\n",
    "- name\n",
    "- addr\n",
    "- city\n",
    "- phone\n",
    "- type (cuisine/category of restaurant)\n",
    "\n",
    "In addition to the two source lists, there is a gold standard file that indicates which Fodor's and Zagat's records refer to the same real-world restaurant. It includes 112 matching pairs (true matches) and 488 non-matching pairs (true negatives) that have been manually annotated.\n",
    "\n",
    "The original dataset is available through the Linkage Library (University of Michigan ICPSR) under the project “Restaurants (Fodors-Zagats), Augmented Version, Fixed Splits (ICPSR 127242)”: https://linkagelibrary.icpsr.umich.edu/linkagelibrary/project/127242/version/V1/view?path=/linkagelibrary/127242/fcr:versions/V1/restaurants_-Fodors-Zagats-&type=folder#tab-dataDocs. For the ease of use, all files used in the analysis have been included in the repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc82ff6",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5fbd7daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fodor's preview: 533 rows, 6 columns\n",
      "    id                       name                    addr          city  \\\n",
      "0  534  arnie morton's of chicago  435 s. la cienega blv.   los angeles   \n",
      "1  535         art's delicatessen     12224 ventura blvd.   studio city   \n",
      "2  536              hotel bel-air    701 stone canyon rd.       bel air   \n",
      "3  537                 cafe bizou     14016 ventura blvd.  sherman oaks   \n",
      "4  538                  campanile     624 s. la brea ave.   los angeles   \n",
      "\n",
      "          phone         type  \n",
      "0  310/246-1501     american  \n",
      "1  818/762-1221     american  \n",
      "2  310/472-1211  californian  \n",
      "3  818/788-3536       french  \n",
      "4  213/938-1447     american  \n",
      "\n",
      "Zagat's preview: 331 rows, 6 columns\n",
      "   id             name                            addr              city  \\\n",
      "0   1   apple pan  the             10801 w. pico blvd.           west la   \n",
      "1   2      asahi ramen             2027 sawtelle blvd.           west la   \n",
      "2   3       baja fresh                 3345 kimber dr.  westlake village   \n",
      "3   4   belvedere  the  9882 little santa monica blvd.     beverly hills   \n",
      "4   5  benita's frites        1433 third st. promenade      santa monica   \n",
      "\n",
      "          phone              type  \n",
      "0  310-475-3585          american  \n",
      "1  310-479-2231      noodle shops  \n",
      "2  805-498-4049           mexican  \n",
      "3  310-788-2306  pacific new wave  \n",
      "4  310-458-2889         fast food  \n",
      "\n",
      "Matches preview: 112 rows, 2 columns\n",
      "   fodors_id  zagats_id\n",
      "0        534        219\n",
      "1        535        220\n",
      "2        536        221\n",
      "3        537        222\n",
      "4        538        223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "fodors = pd.read_csv(\n",
    "    'data/fodors.csv', \n",
    "    # index_col=0, # Leave id column as a regular column to simplify merging\n",
    "    usecols=lambda x: x != 'class', # Exclude 'class' column which is irrelevant to the analysis\n",
    "    quotechar=\"'\", # Ensure apostrophes are properly interpreted\n",
    "    escapechar='\\\\'\n",
    ")\n",
    "\n",
    "zagats = pd.read_csv(\n",
    "    'data/zagats.csv',\n",
    "    # index_col=0, \n",
    "    usecols=lambda x: x != 'class',\n",
    "    quotechar=\"'\",\n",
    "    escapechar='\\\\'\n",
    ")\n",
    "\n",
    "matches = pd.read_csv('data/matches_fodors_zagats.csv')\n",
    "\n",
    "print(f\"Fodor's preview: {fodors.shape[0] } rows, {fodors.shape[1]} columns\")\n",
    "print(fodors.head(5))\n",
    "print()\n",
    "\n",
    "print(f\"Zagat's preview: {zagats.shape[0] } rows, {zagats.shape[1]} columns\")\n",
    "print(zagats.head(5))\n",
    "print()\n",
    "\n",
    "print(f\"Matches preview: {matches.shape[0] } rows, {matches.shape[1]} columns\")\n",
    "print(matches.head(5))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cabb4efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and standardize string fields \n",
    "# to ensure consistency and improve the effectiveness of similarity algorithms\n",
    "def preprocess(df, columns):\n",
    "    df = df.copy()\n",
    "    for col in columns:\n",
    "        df[col] = (\n",
    "            df[col].astype(str) # Ensure all values are strings\n",
    "                   .str.lower() # Convert to lowercase\n",
    "                   .str.replace(r'[^a-z0-9\\s]', '', regex=True) # Remove special characters\n",
    "                   .str.replace(r'\\s+', ' ', regex=True) # Replace multiple spaces with a single space\n",
    "                   .str.strip() # Remove leading/trailing whitespace\n",
    "        )\n",
    "    return df\n",
    "\n",
    "columns_to_preprocess = ['name', 'addr', 'city', 'type']\n",
    "\n",
    "fodors = preprocess(fodors, columns_to_preprocess)\n",
    "zagats = preprocess(zagats, columns_to_preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beb11bd",
   "metadata": {},
   "source": [
    "### Method 0: Regular joins\n",
    "How many restaurants would get matched if we naively use exact matches of names, address, and city?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "621df5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total exact matches found: 26\n",
      "Matches present in gold standard: 26\n",
      "Matches NOT present in gold standard: 0\n"
     ]
    }
   ],
   "source": [
    "# Perform the exact match join\n",
    "matched_df = fodors.merge(\n",
    "    zagats,\n",
    "    on=['name', 'addr', 'city'],\n",
    "    how='inner',\n",
    "    suffixes=('_fodors', '_zagats')\n",
    ")\n",
    "\n",
    "# Check against gold standard matches\n",
    "matched_df['in_gold_standard'] = matched_df.apply(\n",
    "    lambda row: ((matches['fodors_id'] == row['id_fodors']) & \n",
    "                 (matches['zagats_id'] == row['id_zagats'])).any(), axis=1\n",
    ")\n",
    "\n",
    "# Summarize the results\n",
    "total_matched = len(matched_df)\n",
    "matched_in_gold = matched_df['in_gold_standard'].sum()\n",
    "\n",
    "print(f\"Total exact matches found: {total_matched}\")\n",
    "print(f\"Matches present in gold standard: {matched_in_gold}\")\n",
    "print(f\"Matches NOT present in gold standard: {total_matched - matched_in_gold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be22d1e",
   "metadata": {},
   "source": [
    "With regular joins, we would only find 26 matches out of all 112 verified matches (23% of all). Thus, searching for a more efficient method that would take small discrepancies into account is desirable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c964c0b",
   "metadata": {},
   "source": [
    "### Method 1a: Fuzzy Matching with Levenshtein distance\n",
    "Fuzzy matching is a text-matching technique used to identify similar strings by directly comparing their textual similarity, even if they are not exactly identical. It relies purely on character-level or token-level string comparisons.\n",
    "\n",
    "First, we'll use Levenshtein distance which measures the minimum number of single-character edits (insertions, deletions, substitutions) needed to convert one string into another.\n",
    "\n",
    "Levenshtein distance directly compares the strings character-by-character without accounting for token ordering or semantic similarity. Thus, it's sensitive to word order, length differences, and spelling variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a4fffbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Levenshtein scoring: 100%|██████████| 533/533 [00:10<00:00, 51.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Levenshtein pairs preview: 176423 rows, 4 columns\n",
      "   fodors_id  zagats_id      score  actual_match\n",
      "0        534          1  24.393939         False\n",
      "1        534          2  20.227273         False\n",
      "2        534          3  20.138889         False\n",
      "3        534          4  21.028588         False\n",
      "4        534          5  19.746377         False\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing Levenshtein threshold: 100%|██████████| 40/40 [00:00<00:00, 42.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimized Levenshtein Threshold: 78\n",
      "Levenshtein Matching Results:\n",
      "Precision: 0.97\n",
      "Recall:    0.69\n",
      "F1-Score:  0.81\n",
      "Accuracy:  1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Compute normalized Levenshtein similarity score\n",
    "def normalized_levenshtein(s1, s2):\n",
    "    dist = levenshtein_distance(s1, s2)\n",
    "    max_len = max(len(s1), len(s2))\n",
    "    if max_len == 0:\n",
    "        return 100  # identical empty strings\n",
    "    return 100 * (1 - dist / max_len)\n",
    "\n",
    "# Generate all possible pairs with Levenshtein similarity\n",
    "pairs = []\n",
    "for i, f_row in tqdm(fodors.iterrows(), total=len(fodors), desc='Levenshtein scoring'):\n",
    "    for j, z_row in zagats.iterrows():\n",
    "        name_score = normalized_levenshtein(f_row['name'], z_row['name'])\n",
    "        address_score = normalized_levenshtein(f_row['addr'], z_row['addr'])\n",
    "        city_score = normalized_levenshtein(f_row['city'], z_row['city'])\n",
    "        avg_score = (name_score + address_score + city_score) / 3\n",
    "        pairs.append({\n",
    "            'fodors_id': f_row['id'],\n",
    "            'zagats_id': z_row['id'],\n",
    "            'score': avg_score\n",
    "        })\n",
    "\n",
    "lev_df = pd.DataFrame(pairs)\n",
    "\n",
    "# Ground truth labels\n",
    "lev_df['actual_match'] = lev_df.apply(\n",
    "    lambda row: ((matches['fodors_id'] == row['fodors_id']) & \n",
    "                 (matches['zagats_id'] == row['zagats_id'])).any(),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(f\"\\nLevenshtein pairs preview: {lev_df.shape[0]} rows, {lev_df.shape[1]} columns\")\n",
    "print(lev_df.head(5))\n",
    "print()\n",
    "\n",
    "# Optimize threshold for best F1-score\n",
    "thresholds = np.arange(60, 100, 1)\n",
    "best_f1 = 0\n",
    "best_threshold = 0\n",
    "\n",
    "for threshold in tqdm(thresholds, desc=\"Optimizing Levenshtein threshold\"):\n",
    "    lev_df['predicted_match'] = lev_df['score'] >= threshold\n",
    "    f1 = f1_score(lev_df['actual_match'], lev_df['predicted_match'])\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "# Final evaluation using optimized threshold\n",
    "lev_df['predicted_match'] = lev_df['score'] >= best_threshold\n",
    "precision = precision_score(lev_df['actual_match'], lev_df['predicted_match'])\n",
    "recall = recall_score(lev_df['actual_match'], lev_df['predicted_match'])\n",
    "accuracy = accuracy_score(lev_df['actual_match'], lev_df['predicted_match'])\n",
    "\n",
    "# Results\n",
    "print(f\"\\nOptimized Levenshtein Threshold: {best_threshold}\")\n",
    "print(f\"Levenshtein Matching Results:\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall:    {recall:.2f}\")\n",
    "print(f\"F1-Score:  {best_f1:.2f}\")\n",
    "print(f\"Accuracy:  {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c8c757",
   "metadata": {},
   "source": [
    "### Method 1b: Fuzzy Matching with token comparison\n",
    "Next, we use the Python library fuzzywuzzy, specifically the token_set_ratio function, because it efficiently handles variations in word order, extra or missing words, and minor textual differences by comparing sets of words (tokens) between strings.\n",
    "\n",
    "This method is particularly effective for quickly identifying matches when differences are mainly textual rather than semantic or context-based, which are common in the restaurant dataset used in this analysis, for example, matching \"Palm Restaurant\" with \"The Palm Restaurant\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "44bfa64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating token set ratio scores: 100%|██████████| 533/533 [00:40<00:00, 13.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fuzzy pairs preview: 176423 rows, 4 columns\n",
      "   fodors_id  zagats_id      score  actual_match\n",
      "0        534          1  31.000000         False\n",
      "1        534          2  33.000000         False\n",
      "2        534          3  32.333333         False\n",
      "3        534          4  28.000000         False\n",
      "4        534          5  28.666667         False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizing token set ratio threshold:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Optimizing token set ratio threshold:  13%|█▎        | 4/30 [00:00<00:00, 36.96it/s]\n",
      "Optimizing token set ratio threshold:  27%|██▋       | 8/30 [00:00<00:00, 37.79it/s]\n",
      "Optimizing token set ratio threshold:  40%|████      | 12/30 [00:00<00:00, 36.03it/s]\n",
      "Optimizing token set ratio threshold:  53%|█████▎    | 16/30 [00:00<00:00, 36.79it/s]\n",
      "Optimizing token set ratio threshold:  67%|██████▋   | 20/30 [00:00<00:00, 37.60it/s]\n",
      "Optimizing token set ratio threshold:  80%|████████  | 24/30 [00:00<00:00, 38.24it/s]\n",
      "Optimizing token set ratio threshold:  93%|█████████▎| 28/30 [00:00<00:00, 37.78it/s]\n",
      "Optimizing token set ratio threshold: 100%|██████████| 30/30 [00:00<00:00, 37.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimized Threshold: 88\n",
      "Fuzzy Matching Results:\n",
      "Precision: 0.97\n",
      "Recall:    0.89\n",
      "F1-Score:  0.93\n",
      "Accuracy:  1.00\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Generate all possible pairs with name, address, and city similarity\n",
    "pairs = []\n",
    "for i, f_row in tqdm(fodors.iterrows(), total=len(fodors), desc='Generating token set ratio scores'):\n",
    "    for j, z_row in zagats.iterrows():\n",
    "        name_score = fuzz.token_set_ratio(f_row['name'], z_row['name'])\n",
    "        address_score = fuzz.token_set_ratio(f_row['addr'], z_row['addr'])\n",
    "        city_score = fuzz.token_set_ratio(f_row['city'], z_row['city'])\n",
    "        avg_score = (name_score + address_score + city_score) / 3  # Average the three scores\n",
    "        pairs.append({\n",
    "            'fodors_id': f_row['id'],\n",
    "            'zagats_id': z_row['id'],\n",
    "            'score': avg_score\n",
    "        })\n",
    "\n",
    "fuzzy_df = pd.DataFrame(pairs)\n",
    "\n",
    "# Ground truth labels\n",
    "fuzzy_df['actual_match'] = fuzzy_df.apply(\n",
    "    lambda row: ((matches['fodors_id'] == row['fodors_id']) & \n",
    "                 (matches['zagats_id'] == row['zagats_id'])).any(),\n",
    "    axis=1\n",
    ")\n",
    "print(f\"\\nFuzzy pairs preview: {fuzzy_df.shape[0]} rows, {fuzzy_df.shape[1]} columns\")\n",
    "print(fuzzy_df.head(5))\n",
    "print()\n",
    "\n",
    "# Optimize threshold by maximizing F1-score\n",
    "thresholds = np.arange(70, 100, 1)\n",
    "best_f1 = 0\n",
    "best_threshold = 0\n",
    "\n",
    "for threshold in tqdm(thresholds, desc='Optimizing token set ratio threshold'):\n",
    "    fuzzy_df['predicted_match'] = fuzzy_df['score'] >= threshold\n",
    "    f1 = f1_score(fuzzy_df['actual_match'], fuzzy_df['predicted_match'])\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "# Final evaluation using optimized threshold\n",
    "fuzzy_df['predicted_match'] = fuzzy_df['score'] >= best_threshold\n",
    "precision = precision_score(fuzzy_df['actual_match'], fuzzy_df['predicted_match'])\n",
    "recall = recall_score(fuzzy_df['actual_match'], fuzzy_df['predicted_match'])\n",
    "accuracy = accuracy_score(fuzzy_df['actual_match'], fuzzy_df['predicted_match'])\n",
    "\n",
    "# Results\n",
    "print(f\"\\nOptimized Threshold: {best_threshold}\")\n",
    "print(f\"Fuzzy Matching Results:\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall:    {recall:.2f}\")\n",
    "print(f\"F1-Score:  {best_f1:.2f}\")\n",
    "print(f\"Accuracy:  {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e8e2fb",
   "metadata": {},
   "source": [
    "### Method 2: TF-IDF Vectorization + Cosine Similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4552b32a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7c21424",
   "metadata": {},
   "source": [
    "### Method 3: Sentence-BERT Embeddings + Cosine Similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5db201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "765bff8c",
   "metadata": {},
   "source": [
    "### Method 4: LLM Matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26c41b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48321c26",
   "metadata": {},
   "source": [
    "### Method 5: Supervised Machine Learning Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090a974b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c39773d6",
   "metadata": {},
   "source": [
    "### Comparative Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ede6c71",
   "metadata": {},
   "source": [
    "### Conclusion\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
